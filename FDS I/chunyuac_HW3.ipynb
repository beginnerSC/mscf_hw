{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{center}\n",
    "Chun-Yuan (Scott) Chiu\n",
    "\\end{center}\n",
    "\\begin{center}\n",
    "chunyuac@andrew.cmu.edu\n",
    "\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. {-}\n",
    "\n",
    "Let $m_1$ and $m_2$ be the sample first and second moments, respectively, that is \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "m_1 &= \\sum_{i=1}^n X_i/n, \\\\\n",
    "m_2 &= \\sum_{i=1}^n X_i^2/n.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Let $X\\sim\\text{Gamma}(\\alpha, \\beta)$. From the Table of Distribution Facts we know $E(X)=\\alpha/\\beta$, $V(X)=E(X^2)-E(X)^2 = \\alpha/\\beta^2$ and hence \n",
    "\n",
    "$$\n",
    "E(X^2) = \\frac{\\alpha^2 + \\alpha}{\\beta^2}. \n",
    "$$\n",
    "\n",
    "Now matching the first two moments we get\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "m_1 &= \\frac{\\alpha}{\\beta}, \\\\\n",
    "m_2 &= \\frac{\\alpha^2 + \\alpha}{\\beta^2}.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "and thus $m_2 - m_1^2 = \\alpha/\\beta^2$. So\n",
    "\n",
    "$$\n",
    "\\beta = \\frac{\\frac{\\alpha}{\\beta}}{\\frac{\\alpha}{\\beta^2}} = \\frac{m_1}{m_2 - m_1^2}, \n",
    "$$\n",
    "\n",
    "which is the desired estimator for $\\beta$. Plug this back in to $m_1 = \\frac{\\alpha}{\\beta}$ to obtain the estimator for $\\alpha$\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{m_1^2}{m_2 - m_1^2}. \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. {-}\n",
    "\n",
    "### (a) {-}\n",
    "\n",
    "Since $n\\geq 30$, the 95% confidence interval is \n",
    "\n",
    "$$\n",
    "\\left[\\bar x-z_{.025}\\left(\\frac{s}{\\sqrt n}\\right), \\bar x+z_{.025}\\left(\\frac{s}{\\sqrt n}\\right)\\right], \n",
    "$$\n",
    "\n",
    "where $z_{.025}$ is such that $P(Z>z_{.025}) = 2.5\\%$ when $Z$ has the standard normal distribution, whose value can be found to be 1.96 in python as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.ppf(1 - 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, numerically the confidence interval can be evaluated as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.998430432160422, 15.60156956783958)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 14.3\n",
    "s = 4.2\n",
    "n = 40\n",
    "z = norm.ppf(1 - 0.025)\n",
    "\n",
    "(x-z*s/np.sqrt(n), x+z*s/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) {-}\n",
    "\n",
    "Since $n$ is small and the population distribution is unknown, none of the confidence intervals covered in the lecture is applicable. If $\\sigma$ were known, there is Chebyshev's inequality to guarantee \n",
    "\n",
    "$$\n",
    "P\\left(\\bar x - k\\frac{\\sigma}{\\sqrt n} < \\mu < \\bar x + k\\frac{\\sigma}{\\sqrt n}\\right) > 1-\\frac{1}{k^2}.\n",
    "$$\n",
    "\n",
    "Setting $k=\\sqrt{20}$ leads to a 95% confidence interval. But here $\\sigma$ is also unknown. The only clue is the sample standard deviation $s=4.2$, which is not guaranteed to be close to $\\sigma$ either. There might still be a rigorous way to construct a 95% confidence interval but I feel like even if there is one, the constructed confidence interval will not be meaningful, maybe some wide range unless $n$ is large, but if $n$ is large we can just apply CLT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) {-}\n",
    "\n",
    "Since $n<30$ but the population distribution is known to be normal, the 95% confidence interval is \n",
    "\n",
    "$$\n",
    "\\left[\\bar x-t_{.025, 9}\\left(\\frac{s}{\\sqrt n}\\right), \\bar x+t_{.025, 9}\\left(\\frac{s}{\\sqrt n}\\right)\\right], \n",
    "$$\n",
    "\n",
    "where $t_{.025, 9}$ is such that $P(T>t_{.025, 9}) = 2.5\\%$ when $T$ has the $t-$distribution with 9 degrees of freedom, whose value can be found to be 2.262 in python as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2621571627409915"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t.ppf(1-0.025, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, numerically the confidence interval can be evaluated as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.295500994999198, 17.304499005000803)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 14.3\n",
    "s = 4.2\n",
    "n = 10\n",
    "p = t.ppf(1-0.025, 9)\n",
    "\n",
    "(x-p*s/np.sqrt(n), x+p*s/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. {-}\n",
    "\n",
    "### (a) {-}\n",
    "\n",
    "The log likelihood function is \n",
    "\n",
    "$$\n",
    "l(\\lambda) = \\log\\left(\\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{X_i}}{X_i!}\\right) = \\sum_{i=1}^n \\left(-\\lambda + X_i \\log(\\lambda) - \\log(X_i!)\\right).\n",
    "$$\n",
    "\n",
    "Take the first derivative with respect to $\\lambda$ and set to zero to get\n",
    "\n",
    "$$\n",
    "\\frac{dl}{d\\lambda} = \\sum_{i=0}^n\\left(-1+ \\frac{X_i}{\\lambda}\\right) = -n + \\frac{\\sum_{i=1}^n X_i}{\\lambda} = 0\n",
    "$$\n",
    "\n",
    "and hence $\\lambda = \\sum_{i=1}^n X_i/n = \\bar X$. Now check the second derivative \n",
    "\n",
    "$$\n",
    "\\frac{d^2l}{d\\lambda^2} = -\\frac{\\sum_{i=1}^n X_i}{\\lambda^2} \\leq 0.\n",
    "$$\n",
    "\n",
    "Thus we can conclude that $\\bar X$ is indeed the maximum likelihood estimator for $\\lambda$. \n",
    "\n",
    "### (b) {-}\n",
    "\n",
    "Since $E(\\bar X) = \\sum_{i=1}^n E(X_i)/n = \\lambda$, we know $\\bar X$ is an unbiased estimator of $\\lambda$.\n",
    "\n",
    "### (c) {-}\n",
    "\n",
    "The standard error can be found as\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\sqrt{V(\\bar X)} = \\sqrt{V\\left(\\frac{\\sum_{i=1}^n X_i}{n}\\right)}  = \\sqrt{\\frac{\\sum_{i=1}^n V(X_i)}{n^2}} = \\sqrt{\\frac{V(X_i)}{n}} = \\sqrt{\\frac{\\lambda}{n}}.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. {-}\n",
    "\n",
    "Scipy only generates exponential random numbers with parameter 1. To generate exponential random numbers with parameter $\\lambda$ we use this property: If $X\\sim\\text{Exponential}(1)$ then $X/\\lambda \\sim\\text{Exponential}(\\lambda)$. \n",
    "\n",
    "As the result shown below, only 55% of the time the adjusted estimator actually generates a better estimate than the \"worst\" estimator does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55311"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "n = 20\n",
    "l = 10\n",
    "\n",
    "numRepetition = 100000\n",
    "numAdjBetter = 0\n",
    "\n",
    "for _ in range(numRepetition):\n",
    "    sample = expon.rvs(size=n)/l\n",
    "    \n",
    "    lMom2 = np.sqrt(2*n/((sample**2).sum()))\n",
    "    lMom1 = 1/sample.mean()\n",
    "    lAdj = lMom1*(n-1)/n\n",
    "    \n",
    "    if abs(lAdj - l) < abs(lMom2 - l):\n",
    "        numAdjBetter += 1\n",
    "\n",
    "numAdjBetter/numRepetition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. {-}\n",
    "\n",
    "### (a) {-}\n",
    "\n",
    "Since $E(\\hat\\theta_1) = \\frac43 E(\\bar X) = \\frac43 E(X) = \\theta$, we know that $\\hat\\theta_1$ is an unbiased estimator for $\\theta$.\n",
    "\n",
    "### (b) {-}\n",
    "\n",
    "We have \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{bias}(\\hat\\theta_2) &= E(\\hat\\theta_2) - \\theta \\\\\n",
    "&= \\int_0^{\\theta} x f_{X_{(n)}}(x)dx - \\theta \\\\\n",
    "&= \\int_0^{\\theta} \\frac{3nx^{3n}}{\\theta^{3n}}dx - \\theta \\\\\n",
    "&= \\frac{3n\\theta^{3n+1}}{(3n+1)\\theta^{3n}} - \\theta \\\\\n",
    "&= -\\frac{\\theta}{3n+1} \\neq 0.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Thus $\\hat\\theta_2$ is biased. \n",
    "\n",
    "### (c) {-}\n",
    "\n",
    "First we find MSE for both estimators: \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{MSE}(\\hat\\theta_2) &= V(\\hat\\theta_2) + \\text{bias}^2(\\hat\\theta_2)\\\\\n",
    "&= \\left(\\frac{3n}{(3n+2)(3n+1)^2} + \\frac{1}{(3n+1)^2}\\right)\\theta^2\\\\\n",
    "&= \\frac{2\\theta^2}{(3n+1)(3n+2)}, \\\\\n",
    "\\text{MSE}(\\hat\\theta_1) &= V(\\hat\\theta_1) = \\frac{16}{9}V(\\bar X) = \\frac{16}{9n}\\frac{3}{80}\\theta^2 = \\frac{\\theta^2}{15n}. \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Thus $\\text{MSE}(\\hat\\theta_2) < \\text{MSE}(\\hat\\theta_1)$ if and only if \n",
    "\n",
    "$$\n",
    "\\frac{2}{(3n+1)(3n+2)} < \\frac{1}{15n}. \n",
    "$$\n",
    "\n",
    "Since $n>0$, this is equivalent to $30n < (3n+1)(3n+2)$, which solves to $\\{n > 2.23385\\} \\cup \\{n < 0.09948\\}$. Since $n$ can only be integers, this is the same as $n>2$. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
